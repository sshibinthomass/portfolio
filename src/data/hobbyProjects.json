{
    "en": [
        {
            "id": 13,
            "title": "MediMind",
            "description": "An AI-powered personal medical assistant that helps users track health metrics, manage medical information, and receive intelligent health guidance. Features dual modes for patients and healthcare providers, real-time health dashboard, and multi-LLM support",
            "category": "agentic-llm",
            "images": [
                "/images/project/mediMind.jpg"
            ],
            "youtubeLink": "https://youtu.be/ALTnhbkpddc",
            "github": "https://github.com/sshibinthomass/nucleate-hack-medi-minds",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "November 2025",
            "technologies": [
                { "name": "React", "description": "Frontend library for building the interactive health dashboard UI" },
                { "name": "Vite", "description": "Fast build tool and development server for the React frontend" },
                { "name": "FastAPI", "description": "High-performance Python backend framework for REST API endpoints" },
                { "name": "LangChain", "description": "Framework for building AI-powered applications with LLM orchestration" },
                { "name": "LangGraph", "description": "Library for creating stateful, multi-actor AI agent workflows" },
                { "name": "Groq", "description": "LLM provider integration for ultra-fast AI inference" },
                { "name": "OpenAI", "description": "GPT model integration for intelligent medical assistance" },
                { "name": "Google Gemini", "description": "Google's multimodal AI model for conversational intelligence" },
                { "name": "Ollama", "description": "Local LLM support for running AI models offline" },
                { "name": "MCP (Model Context Protocol)", "description": "Protocol for integrating external tools and data sources with AI agents" },
                { "name": "Python", "description": "Backend programming language powering the API and AI logic" },
                { "name": "Pandas", "description": "Data analysis library for health metrics processing" },
                { "name": "Plotly", "description": "Interactive visualization library for health data charts" },
                { "name": "scikit-learn", "description": "Machine learning library for health forecasting and predictions" },
                { "name": "DuckDB", "description": "Embedded analytics database for efficient data querying" },
                { "name": "Gmail API", "description": "Email integration for sending medical-related communications" }
            ],
            "detailedDescription": "<p><strong>Medi-Mind</strong> is a comprehensive AI-powered healthcare management platform built with React and FastAPI that bridges the gap between patients and healthcare providers. It features a <strong>personal medical assistant</strong> with real-time health tracking (steps, calories, heart rate, blood oxygen, water intake, mood, sleep, energy levels), interactive health metric visualization with Plotly charts, and intelligent AI-powered medical guidance. The platform supports <strong>multiple LLM providers</strong> including OpenAI GPT, Google Gemini, Groq, and local Ollama models, enabling flexible and context-aware medical conversations. It offers <strong>dual use cases</strong>: a Medical Assistant mode for patients to track and understand their health, and a Doctor Assistant mode for healthcare professionals with patient management, analytics, and age group demographics. Key features include <strong>MCP (Model Context Protocol)</strong> integration for external tool connectivity, <strong>Gmail integration</strong> for medical communications, weather and date context awareness, health alerts when metrics fall below recommended levels, and <strong>machine learning-based health forecasting</strong> using scikit-learn and statsmodels. Built using LangChain and LangGraph for sophisticated AI agent workflows, the system provides empathetic, professional, and data-driven health insights while maintaining a modern, responsive UI with animated health widgets and real-time data synchronization.</p>"
        },
            {
            "id": 12,
            "title": "GenDesign",
            "description": "GenDesign is an intelligent structural engineering assistant that helps engineers design optimal beams through natural conversation in English and German. It combines advanced AI orchestration using LangGraph, physics-based calculations, machine learning models, and interactive 3D visualization to provide comprehensive beam analysis and optimization.",
            "category": "agentic-llm",
            "images": [
                "/images/project/genDesign.jpg"
            ],
            "youtubeLink": "https://youtu.be/jf_8_DkVa8s",
            "github": "https://github.com/sshibinthomass/BKW-Design-Agent",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "October 2025",
            "technologies": [
                    { "name": "Python", "description": "Backend language for Flask app and AI orchestration" },
                { "name": "Flask", "description": "Web framework for REST API and server logic" },
                { "name": "Anthropic Claude", "description": "LLM for natural language conversation" },
                { "name": "Google Gemini", "description": "AI model for enhanced conversations" },
                { "name": "LangGraph", "description": "Agentic AI orchestration framework" },
                { "name": "SciPy", "description": "Scientific computing for beam optimization" },
                { "name": "scikit-learn", "description": "ML library for deflection prediction" },
                { "name": "Pandas", "description": "Data manipulation and CSV handling" },
                { "name": "NumPy", "description": "Numerical computing for calculations" },
                { "name": "Plotly", "description": "Interactive 3D visualization library" },
                { "name": "MCP Tools", "description": "Model Context Protocol integration" },
                { "name": "JavaScript", "description": "Frontend scripting and UI interactions" },
                { "name": "HTML5", "description": "Semantic markup and file uploads" },
                { "name": "CSS3", "description": "Modern styling with Flexbox and Grid" }
            ],
            "detailedDescription": "<p><strong>GenDesign</strong> is an AI-powered structural engineering assistant that enables natural language beam design in <em>English and German</em>, combining <strong>LangGraph agentic AI orchestration</strong>, <strong>Anthropic Claude LLM</strong> for conversation management, <strong>Random Forest ML models</strong> for deflection prediction, <strong>SciPy-based optimization</strong> for volume minimization, and <strong>Plotly 3D visualization</strong> for interactive beam rendering, with support for <em>Steel (IPE profiles)</em>, <em>Wood</em>, and <em>Concrete</em> materials, plus intelligent task management with vacation approval logic and a historical database of 3000+ successful designs for pattern recognition and recommendations.</p>"
        },
        {
            "id": 11,
            "title": "AskLeo",
            "description": "AskLeo is an AI-powered negotiation assistant that automates business negotiations with vendors using multi-agent conversations, voice interface, and integrated email/calendar automation.",
            "category": "agentic-llm",
            "images": [
                "/images/project/askLeo.jpg"
            ],
            "youtubeLink": "https://youtu.be/YjnY0FsknZA",
            "github": "https://github.com/sshibinthomass/Start-Munich-Hack-AskLeo",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "November 2025",
            "technologies": [
                { "name": "React", "description": "Frontend UI framework" },
                { "name": "Vite", "description": "Build tool & dev server" },
                { "name": "Recharts", "description": "Data visualization charts" },
                { "name": "CSS", "description": "Styling" },
                { "name": "Python", "description": "Backend programming language" },
                { "name": "FastAPI", "description": "REST API framework" },
                { "name": "Uvicorn", "description": "ASGI server" },
                { "name": "LangChain", "description": "LLM orchestration framework" },
                { "name": "LangGraph", "description": "Multi-agent workflow engine" },
                { "name": "OpenAI GPT-4", "description": "AI chat & reasoning" },
                { "name": "OpenAI Whisper", "description": "Speech-to-text" },
                { "name": "ElevenLabs", "description": "Text-to-speech" },
                { "name": "Gmail API", "description": "Email automation" },
                { "name": "Google Calendar API", "description": "Meeting scheduling" },
                { "name": "Pandas", "description": "Data processing" },
                { "name": "DuckDB", "description": "Embedded analytics database" },
                { "name": "Tavily", "description": "Web search API" },
                { "name": "MCP", "description": "Tool integration protocol" }
            ],
            "detailedDescription": "<p><strong>AskLeo</strong> is an intelligent AI negotiation assistant built for the Start Munich Hackathon. It automates business negotiations with vendors, manages communications via email and calendar, and provides a voice-enabled interface for seamless user interaction.</p><ul><li><strong>Automated Negotiation:</strong> AI agents negotiate with vendors using strategic conversation tactics</li><li><strong>Multi-Agent Communication:</strong> Two AI agents can negotiate with each other automatically</li><li><strong>Voice Interface:</strong> Speak with the AI using OpenAI Whisper and hear responses via ElevenLabs</li><li><strong>Email Integration:</strong> Sends confirmation emails after successful deals via Gmail API</li><li><strong>Calendar Scheduling:</strong> Automatically schedules follow-up meetings via Google Calendar</li><li><strong>Product Knowledge:</strong> Integrated product catalog for intelligent recommendations</li></ul>"
        },
        {
            "id": 10,
            "title": "Slug Flow Crystallization",
            "description": "Data-based Modeling of Slug Flow Crystallization with Uncertainty Quantification",
            "category": "agentic-llm",
            "images": [
                "/images/project/Slug_Flow_Crystallization1.jpeg"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/MLME_SFC_13",
            "appLink": "",
            "purpose": "MLME Project",
            "duration": "2 months",
            "date": "July 2025",
            "technologies": [
                "NARX",
                "CQR",
                "Tensorflow",
                "Data Preprocessing",
                "Clustering",
                "Time Series"
            ],
            "detailedDescription": "<h1>Data-based Modeling of Slug Flow Crystallization with Uncertainty Quantification</h1><p><strong>Authors:</strong></p><ul><li>Shibin Thomas Stanley Paul - 259782</li><li>Aadhithya Krishnakumar - 258741</li><li>Nishitkumar Karkar - 257529</li><li>Sankar Santhosh Nair - 258852</li></ul><h2>Abstract</h2><p>This report presents a machine learning framework for modeling slug flow crystallization processes with uncertainty quantification. The approach combines three core components:<ul><li>Unsupervised clustering to detect operational regimes</li><li>Nonlinear Autoregressive with Exogenous Inputs (NARX) neural networks for dynamic modeling</li><li>Conformalized Quantile Regression (CQR) for providing reliable prediction intervals</li></ul>Results demonstrate accurate regime separation, strong model generalization, and calibrated uncertainty estimates, facilitating robust control in pharmaceutical crystallization applications.</p><h2>I. Introduction</h2><p>Slug Flow Crystallization (SFC) is widely used in pharmaceutical manufacturing for its ability to produce consistent particle sizes. However, challenges arise due to the dynamic and nonlinear nature of crystallization, compounded by noise in particle size measurements such as d10, d50, and d90.</p><h2>II. Data Analysis and Clustering</h2><h3>A. Data Preprocessing and Quality Assessment</h3><p>The dataset comprises 98 time series files with process variable measurements. Seven files containing abnormal ranges in particle size values were excluded. For the remaining 91 files:</p><ul><li>Duplicates and empty entries were removed</li><li>Outliers were filtered using custom thresholding and Interquartile Range (IQR) methods</li><li>IQR-based filtering was selected due to better robustness</li></ul><h3>B. Clustering Analysis and Regime Identification</h3><p>K-means clustering with k equal to 2 identified two regimes. Metrics: Silhouette Score - 0.389, Calinski-Harabasz Score - 23.805, Davies-Bouldin Score - 1.459.</p><h2>III. NARX Model Development</h2><p>NARX models were developed separately for each cluster. The models use deep feedforward networks with six hidden layers: 1024 to 768 to 512 to 256 to 128 to 6. Activation: SELU. Regularization: dropout from 0.4 to 0.2 and L2 penalty.</p><h2>IV. Uncertainty Quantification</h2><p>Conformalized Quantile Regression with 90% coverage validated across all variables.</p><h2>V. Results</h2><p>Uncertainty coverage averaged 99.9% for closed loop and 97.2% for open loop cases, confirming reliability for real-world deployment.</p><h2>VI. Conclusion</h2><p>The proposed framework successfully integrates unsupervised clustering, deep temporal modeling, and predictive uncertainty quantification. It achieves strong generalization, reliable interval estimates, and operational regime separation, making it suitable for real-time process control in pharmaceutical crystallization.</p>"
        },
        {
            "id": 9,
            "title": "Langgraph Core",
            "description": "Open-source LangGraph implementation patterns and examples",
            "category": "agentic-llm",
            "images": [
                "/images/project/Langgraph-Core1.jpeg"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/Langgraph-Core",
            "appLink": "",
            "purpose": "Open Source Project",
            "duration": "1 month",
            "date": "May 2025",
            "technologies": [
                "Open-AI",
                "Groq",
                "Gemini",
                "Ollama",
                "LLM",
                "LangGraph",
                "Streamlit"
            ],
            "detailedDescription": "<h2>LangGraph Core</h2><p>A comprehensive open-source project demonstrating LangGraph implementation patterns with multiple LLM providers.</p><h3>Features</h3><ul><li>Multi-provider LLM support (OpenAI, Groq, Gemini, Ollama)</li><li>Graph-based agent workflows</li><li>Streamlit UI for interactive demos</li><li>Educational examples and documentation</li><li>Production-ready patterns for building agentic applications</li></ul>"
        },
        {
            "id": 8,
            "title": "Munich Sushi Chatbot",
            "description": "AI chatbot for finding sushi restaurants in Munich with parking assistance",
            "category": "agentic-llm",
            "images": [
                "/images/project/Munich-Sushi1.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/8AhdfVI-oU8?si=_zJ6zAP9A762ZIFO",
            "github": "https://github.com/sshibinthomass/Munich-sushi-Chatbot",
            "appLink": "",
            "purpose": "Personal Project",
            "duration": "2 weeks",
            "date": "June 2025",
            "technologies": [
                "Open-AI",
                "LLM",
                "RAG",
                "LangGraph",
                "Streamlit",
                "ChromaDB",
                "MCP",
                "Google Maps",
                "Web RAG"
            ],
            "detailedDescription": "<h2>Munich Sushi Chatbot</h2><p>An AI-powered chatbot that helps users discover sushi restaurants in Munich with integrated parking assistance.</p><h3>Features</h3><ul><li><strong>Sushi Restaurant Discovery:</strong> Find the best sushi places based on preferences, ratings, and location</li><li><strong>Parking Assistance:</strong> Get nearby parking information and availability</li><li><strong>Contextual Information:</strong> Reviews, hours, directions, and more</li></ul><h3>Technology Stack</h3><ul><li><strong>LangGraph:</strong> For workflow orchestration and agent logic</li><li><strong>ChromaDB:</strong> Vector store for semantic search</li><li><strong>MCP (Model Context Protocol):</strong> Modular tool servers</li><li><strong>Google Maps API:</strong> Location and parking data</li><li><strong>Streamlit:</strong> User interface</li><li><strong>OpenAI:</strong> Language model backbone</li></ul>"
        },
        {
            "id": 6,
            "title": "NaviBot",
            "description": "DRO-CO Bot - AI-powered Humanoid Robot for COVID SOP Compliance",
            "category": "robotics-iot",
            "images": [
                "/images/project/NaviBot1.jpeg",
                "/images/project/NaviBot2.jpeg",
                "/images/project/NaviBot3.jpeg",
                "/images/project/NaviBot4.jpeg",
                "/images/project/NaviBot5.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/QqrCg2vfLW0",
            "github": "",
            "appLink": "",
            "purpose": "College Final Project",
            "duration": "1 Year",
            "date": "1 March 2022",
            "technologies": [
                "Deep Learning",
                "Machine Learning",
                "Flask",
                "Robotics",
                "Django"
            ],
            "detailedDescription": "<h3>Funding & Recognition</h3><p>  This project was officially  <strong>funded under the Student Projects Scheme (SPS)</strong> by the  <strong>Tamil Nadu State Council for Science and Technology (TANSCST)</strong>, an initiative under the Government of Tamil Nadu, during the academic year  2021–2022.</p><p>  The <strong>TANSCST Student Projects Scheme</strong> is a competitive funding  program that supports innovative and socially impactful final-year student  projects in science, engineering, and technology.</p><h3>Problem Statement</h3><p>  In response to the COVID-19 pandemic, there was an urgent requirement for  contactless systems to enforce Standard Operating Procedures (SOPs) like  temperature checks, mask compliance, and attendance in public environments.</p><h3>Project Summary</h3><p>  I conceptualized, designed, programmed, and fabricated a humanoid robot named  <strong>DRO-CO Bot</strong>, an AI-powered, IoT-integrated robotic assistant.  It can detect face masks, measure temperature without contact, recognize faces  for automatic attendance, and interact with users using speech recognition and  AI-driven responses.</p><h3>Features and Capabilities</h3><ul>  <li>Face mask detection using TensorFlow and MobileNetV2</li>  <li>Real-time face recognition using OpenCV and face_recognition library</li>  <li>Contactless temperature sensing using MLX90614 IR sensor</li>  <li>Speech recognition and voice response using Python, pyttsx3, and Google Speech API</li>  <li>AI-powered assistant with Wikipedia, WolframAlpha, and OpenWeather integrations</li>  <li>WhatsApp automation via Selenium for live reporting and alerts</li>  <li>Servo motor-based robotic arm with 3 DOF controlled by Arduino</li>  <li>Ultrasonic-based object detection and crowd monitoring</li>  <li>Real-time attendance and temperature data logging</li></ul><h3>Technical Implementation</h3><ul>  <li>Developed both forward and inverse kinematics for the robotic arm using D-H parameters</li>  <li>Calculated torque, stress, strain, buckling load for robot joints using PLA structural material</li>  <li>Designed and 3D printed all mechanical components using Fusion 360 and PLA filament</li>  <li>Established I2C communication between Raspberry Pi and Arduino for sensor control</li>  <li>Used servo motors (MG996R, RDS3115MG) for joint control with PID-based position feedback</li></ul><h3>Outcome</h3><ul>  <li>Successfully fabricated and tested a fully functional autonomous COVID-19 SOP enforcement robot</li>  <li>Recognized faces and recorded attendance with >95% accuracy</li>  <li>Detected mask violations in real-time and notified users via WhatsApp</li>  <li>Tested successfully in a live industrial environment</li></ul><h3>Project Budget</h3><p>Total Cost: ₹28,601 INR (Optimized through open-source tools and affordable components)</p>"
        },
        {
            "id": 4,
            "title": "ARcadium",
            "description": "IOTAR Application - AR and IoT for Enhanced Learning",
            "category": "web-app",
            "images": [
                "/images/project/ARcadium1.jpeg",
                "/images/project/ARcadium2.jpeg",
                "/images/project/ARcadium3.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/KQdLGSpzPxI",
            "github": "",
            "appLink": "",
            "purpose": "NSTF Codissia",
            "duration": "2 year",
            "date": "4 March 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Augmented Reality"
            ],
            "detailedDescription": "<p align=\"justify\">&emsp;Augmented reality (AR) is a technology that overlays digital information such as sounds, videos, and graphics on top of the real-world environment. AR can enhance the learning experience by providing interactive and immersive content that can stimulate learners' motivation, attention, and understanding. Internet of things (IoT) is a technology that connects physical devices, such as sensors, cameras, and actuators, to the internet and enables data transmission and synchronization.<br><br>\n\n    &emsp;IOTAR is a term that combines AR and IoT to create a novel learning paradigm that leverages the advantages of both technologies. IOTAR can provide learners with contextualized and personalized learning content that is based on their location, preferences, and performance.<br><br>\n\n<b>Our application is developed using AR for employee and student learning using IOTAR. Our application has the following features and benefits:</b>\n<ul>\n<li>It uses AR to display 3D models of objects or concepts that are relevant to the learning objectives, such as anatomy, chemistry, physics, or engineering. Learners can explore the models from different angles and perspectives, zoom in and out, and rotate them.</li>\n<li>It uses IoT to collect data from sensors or devices to adjust the difficulty level, feedback, or content of the learning activities according to the learners' needs and preferences.</li>\n<li>It uses AR to create gamified learning experiences that can motivate and challenge learners with points, badges, leaderboards, or quests.</li>\n<li>It uses IoT to enable collaboration and communication among learners who are located in different places.</li>\n<li>It uses AR to create a magical feeling of a 3D object appearing on top of the physical world.</li>\n</ul><br>\n\n<b>Our application can be used for various purposes and contexts, such as:</b>\n<ul>\n<li>Employee training: Our application can help employees learn new skills or update their knowledge in a fun and engaging way.</li>\n<li>Student education: Our application can help students learn complex or abstract concepts in a visual and interactive way.</li>\n<li>Lifelong learning: Our application can help anyone who wants to learn something new or pursue their interests in a flexible and convenient way.</li>\n</ul>\n</p>"
        },
        {
            "id": 3,
            "title": "SubMerge",
            "description": "Exploring the Aquatic Wonders - A Virtual Reality Underwater Museum",
            "category": "web-app",
            "images": [
                "/images/project/SubMerge1.jpeg",
                "/images/project/SubMerge2.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/9ubWJePQCwg",
            "github": "",
            "appLink": "https://drive.google.com/file/d/1SkCRXHEn5xs_H8E9z1KcGtNdg5EASb57/view?usp=drive_link",
            "purpose": "SIH (Software edition)",
            "duration": "2 weeks",
            "date": "6 March 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Virtual Reality"
            ],
            "detailedDescription": "<h1>VR Underwater Experience - Project Documentation</h1><h2>Overview</h2><p>  I developed an immersive Virtual Reality (VR) application designed for Android  devices using Unity and Google VR. This application provides users with an  interactive underwater experience, enabling them to explore four unique  environments: Tower, Ship, Dance, and Ride. The user interacts with the  virtual world through intuitive gaze-based navigation.</p><h2>Main Menu and Navigation</h2><p>  Upon launching the application, the Unity logo is displayed. After loading, the user is greeted with a main menu  offering the following options:</p><ul>  <li>Tower</li>  <li>Dance</li>  <li>Ship</li>  <li>Ride</li></ul><p>  The menu is controlled using gaze-based input. Users simply look at one of the  menu options to make a selection.</p><h2>Scenes and Features</h2><h3>Tower Section</h3><p>  Selecting the 'Tower' option transports the user to a serene underwater  environment situated on the seabed. The scene includes:</p><ul>  <li>Blue sharks swimming across the scene.</li>  <li>A central tower-like structure providing architectural depth.</li>  <li>Pink and light blue aquatic creatures adding vibrant marine life.</li>  <li>Realistic seabed details such as rocks, seaweed, and marine flora.</li>  <li>Darker colored sharks and white whales gliding through the water.</li>  <li>    A glowing green orb positioned near the ocean floor to create intrigue.  </li></ul><h3>Ship Section</h3><p>  The 'Ship' environment features a large, partially submerged ship, viewed from  various angles as the camera pans dynamically.</p><h3>Dance Section</h3><p>  In the 'Dance' section, I created a choreographed sequence where marine  animals move in synchronization, resembling a dance performance.</p><h3>Ride Section</h3><p>  Choosing 'Ride' offers users a guided boat-like journey through the underwater  world.</p><h2>Technology Stack</h2><ul>  <li>    <strong>Unity:</strong> Game engine used for developing the VR experience.  </li>  <li>    <strong>Google VR SDK:</strong> Integrated for enabling VR support on Android devices.  </li>  <li>    <strong>Blender:</strong> Used to model and animate 3D marine life.  </li>  <li>    <strong>C#:</strong> Programming language used within Unity for scripting.  </li></ul>"
        },
        {
            "id": 2,
            "title": "Spikora",
            "description": "RosaryPlantHouse.com – E-commerce Web Application for Plant Lovers",
            "category": "web-app",
            "images": [
                "/images/project/Spikora1.jpeg",
                "/images/project/Spikora2.jpeg"
            ],
            "youtubeLink": "",
            "github": "",
            "appLink": "https://www.rosaryplanthouse.com",
            "purpose": "Rosary Plant House",
            "duration": "2 weeks",
            "date": "7 March 2022",
            "technologies": [
                "HTML",
                "CSS",
                "JavaScript",
                "Ecommerce"
            ],
            "detailedDescription": "<h2>RosaryPlantHouse.com – E-commerce Web Application</h2><p>  I developed <strong>RosaryPlantHouse.com</strong>, a static-first e-commerce  website specifically tailored for plant enthusiasts. This project represents a  complete end-to-end solution I created, encompassing everything from  architecture and data management to user experience and operational design.  The platform was designed for performance, simplicity, and minimal operational  overhead, and it showcases my skills in creative problem-solving, front-end  engineering, and strategic product thinking.</p><h3><strong>Executive Summary</strong></h3><p>  The Rosary Plant House application was engineered entirely as a static website  with client-side JavaScript powering all interactivity. This includes a  sophisticated product catalogue, cart management system, and a novel  WhatsApp-based checkout mechanism I designed as an innovative alternative to  traditional e-commerce infrastructure.</p><h3><strong>System Architecture and Technology Stack</strong></h3><h4><strong>'Static-First' E-Commerce Engine</strong></h4><p>  I built the site using a Jamstack approach, delivering pre-built HTML pages  such as <code>catalogue.html</code> and <code>restocked.html</code> for  performance and security. All cart, filtering, and UI logic is powered by  client-side JavaScript, removing the need for a backend server.</p><h4><strong>Performance, Security, and Operational Efficiency</strong></h4><ul>  <li><strong>Performance:</strong> Hosted on a CDN for fast load times.</li>  <li><strong>Security:</strong> No backend = minimal attack surface.</li>  <li>    <strong>Maintenance:</strong> No server or database to maintain,    dramatically lowering costs.  </li></ul><h4><strong>Technology Stack</strong></h4><ul>  <li><strong>HTML5, CSS:</strong> For structure and responsive design.</li>  <li>    <strong>JavaScript:</strong> For cart, filtering, and checkout integration.  </li>  <li>    <strong>Web Storage API (localStorage):</strong> To persist cart state    across sessions.  </li></ul><h4><strong>WhatsApp Checkout – 'Conversational Commerce'</strong></h4><p>  I built a unique client-side checkout that uses the WhatsApp API. Upon  clicking 'Place Order':</p><ol>  <li>JavaScript compiles the cart into a formatted message.</li>  <li>    It URL-encodes the message and redirects the user to WhatsApp via a    <code>https://wa.me</code> link.  </li>  <li>    The business receives the message directly and confirms the order manually.  </li></ol><h3><strong>Conclusion</strong></h3><p>  This project is a complete, real-world example of intelligent design under  tight constraints. It demonstrates my full-stack problem-solving ability, my  proficiency in static web development, and my creative use of existing tools  (like WhatsApp) to solve business challenges.</p>"
        }
    ],
    "de": [
        {
            "id": 13,
            "title": "MediMind",
            "description": "Ein KI-gestützter persönlicher medizinischer Assistent, der Benutzern hilft, Gesundheitsmetriken zu verfolgen, medizinische Informationen zu verwalten und intelligente Gesundheitsberatung zu erhalten. Bietet duale Modi für Patienten und Gesundheitsdienstleister, Echtzeit-Gesundheitsdashboard und Multi-LLM-Unterstützung",
            "category": "agentic-llm",
            "images": [
                "/images/project/mediMind.jpg"
            ],
            "youtubeLink": "https://youtu.be/ALTnhbkpddc",
            "github": "https://github.com/sshibinthomass/nucleate-hack-medi-minds",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "November 2025",
            "technologies": [
                { "name": "React", "description": "Frontend-Bibliothek zum Erstellen des interaktiven Gesundheitsdashboard-UI" },
                { "name": "Vite", "description": "Schnelles Build-Tool und Entwicklungsserver für das React-Frontend" },
                { "name": "FastAPI", "description": "Hochperformantes Python-Backend-Framework für REST-API-Endpunkte" },
                { "name": "LangChain", "description": "Framework zum Erstellen von KI-gestützten Anwendungen mit LLM-Orchestrierung" },
                { "name": "LangGraph", "description": "Bibliothek zum Erstellen von zustandsbehafteten, Multi-Akteur-KI-Agenten-Workflows" },
                { "name": "Groq", "description": "LLM-Anbieter-Integration für ultraschnelle KI-Inferenz" },
                { "name": "OpenAI", "description": "GPT-Modell-Integration für intelligente medizinische Unterstützung" },
                { "name": "Google Gemini", "description": "Googles multimodales KI-Modell für konversationelle Intelligenz" },
                { "name": "Ollama", "description": "Lokale LLM-Unterstützung zum Offline-Ausführen von KI-Modellen" },
                { "name": "MCP (Model Context Protocol)", "description": "Protokoll zur Integration externer Tools und Datenquellen mit KI-Agenten" },
                { "name": "Python", "description": "Backend-Programmiersprache für die API und KI-Logik" },
                { "name": "Pandas", "description": "Datenanalysebibliothek zur Verarbeitung von Gesundheitsmetriken" },
                { "name": "Plotly", "description": "Interaktive Visualisierungsbibliothek für Gesundheitsdaten-Diagramme" },
                { "name": "scikit-learn", "description": "Machine-Learning-Bibliothek für Gesundheitsprognosen und Vorhersagen" },
                { "name": "DuckDB", "description": "Eingebettete Analytics-Datenbank für effiziente Datenabfragen" },
                { "name": "Gmail API", "description": "E-Mail-Integration zum Senden medizinischer Kommunikation" }
            ],
            "detailedDescription": "<p><strong>Medi-Mind</strong> ist eine umfassende KI-gestützte Gesundheitsverwaltungsplattform, die mit React und FastAPI erstellt wurde und die Lücke zwischen Patienten und Gesundheitsdienstleistern schließt. Es bietet einen <strong>persönlichen medizinischen Assistenten</strong> mit Echtzeit-Gesundheitsverfolgung (Schritte, Kalorien, Herzfrequenz, Blutsauerstoff, Wasseraufnahme, Stimmung, Schlaf, Energieniveaus), interaktive Visualisierung von Gesundheitsmetriken mit Plotly-Diagrammen und intelligente KI-gestützte medizinische Beratung. Die Plattform unterstützt <strong>mehrere LLM-Anbieter</strong> einschließlich OpenAI GPT, Google Gemini, Groq und lokale Ollama-Modelle, was flexible und kontextbewusste medizinische Gespräche ermöglicht. Es bietet <strong>zwei Anwendungsfälle</strong>: einen Medizinischen Assistenten-Modus für Patienten zur Verfolgung und zum Verständnis ihrer Gesundheit und einen Arzt-Assistenten-Modus für Gesundheitsfachkräfte mit Patientenverwaltung, Analysen und Altersgruppen-Demografie. Zu den Hauptfunktionen gehören <strong>MCP (Model Context Protocol)</strong>-Integration für externe Tool-Konnektivität, <strong>Gmail-Integration</strong> für medizinische Kommunikation, Wetter- und Datumskontextbewusstsein, Gesundheitswarnungen, wenn Metriken unter empfohlene Werte fallen, und <strong>maschinelles Lernen-basierte Gesundheitsprognosen</strong> mit scikit-learn und statsmodels. Erstellt mit LangChain und LangGraph für ausgeklügelte KI-Agenten-Workflows, bietet das System empathische, professionelle und datengesteuerte Gesundheitseinblicke bei gleichzeitiger Beibehaltung einer modernen, responsiven Benutzeroberfläche mit animierten Gesundheits-Widgets und Echtzeit-Datensynchronisation.</p>"
        },
        {
            "id": 12,
            "title": "GenDesign",
            "description": "GenDesign ist ein intelligenter Strukturingenieur-Assistent, der Ingenieuren hilft, optimale Träger durch natürliche Konversation auf Englisch und Deutsch zu entwerfen. Es kombiniert fortgeschrittene KI-Orchestrierung mit LangGraph, physikbasierte Berechnungen, Machine-Learning-Modelle und interaktive 3D-Visualisierung für umfassende Trägeranalyse und -optimierung.",
            "category": "agentic-llm",
            "images": [
                "/images/project/genDesign.jpg"
            ],
            "youtubeLink": "https://youtu.be/jf_8_DkVa8s",
            "github": "https://github.com/sshibinthomass/BKW-Design-Agent",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "Oktober 2025",
            "technologies": [
                { "name": "Python", "description": "Backend-Sprache für Flask-App und KI-Orchestrierung" },
                { "name": "Flask", "description": "Web-Framework für REST-API und Server-Logik" },
                { "name": "Anthropic Claude", "description": "LLM für natürliche Sprachkonversation" },
                { "name": "Google Gemini", "description": "KI-Modell für verbesserte Konversationen" },
                { "name": "LangGraph", "description": "Agentic AI-Orchestrierungsframework" },
                { "name": "SciPy", "description": "Wissenschaftliches Computing für Trägeroptimierung" },
                { "name": "scikit-learn", "description": "ML-Bibliothek für Durchbiegungsvorhersage" },
                { "name": "Pandas", "description": "Datenmanipulation und CSV-Verarbeitung" },
                { "name": "NumPy", "description": "Numerisches Computing für Berechnungen" },
                { "name": "Plotly", "description": "Interaktive 3D-Visualisierungsbibliothek" },
                { "name": "MCP Tools", "description": "Model Context Protocol-Integration" },
                { "name": "JavaScript", "description": "Frontend-Scripting und UI-Interaktionen" },
                { "name": "HTML5", "description": "Semantisches Markup und Datei-Uploads" },
                { "name": "CSS3", "description": "Modernes Styling mit Flexbox und Grid" }
            ],
            "detailedDescription": "<p><strong>GenDesign</strong> ist ein KI-gestützter Strukturingenieur-Assistent, der Trägerdesign in natürlicher Sprache auf <em>Englisch und Deutsch</em> ermöglicht und <strong>LangGraph agentic AI-Orchestrierung</strong>, <strong>Anthropic Claude LLM</strong> für Konversationsmanagement, <strong>Random Forest ML-Modelle</strong> für Durchbiegungsvorhersage, <strong>SciPy-basierte Optimierung</strong> zur Volumenminimierung und <strong>Plotly 3D-Visualisierung</strong> für interaktives Träger-Rendering kombiniert, mit Unterstützung für <em>Stahl (IPE-Profile)</em>, <em>Holz</em> und <em>Beton</em> Materialien, plus intelligentes Aufgabenmanagement mit Urlaubsgenehmigungslogik und einer historischen Datenbank mit über 3000 erfolgreichen Designs für Mustererkennung und Empfehlungen.</p>"
        },
        {
            "id": 11,
            "title": "AskLeo",
            "description": "AskLeo ist ein KI-gestützter Verhandlungsassistent, der Geschäftsverhandlungen mit Lieferanten durch Multi-Agenten-Konversationen, Sprachschnittstelle und integrierte E-Mail/Kalender-Automatisierung automatisiert.",
            "category": "agentic-llm",
            "images": [
                "/images/project/askLeo.jpg"
            ],
            "youtubeLink": "https://youtu.be/YjnY0FsknZA",
            "github": "https://github.com/sshibinthomass/Start-Munich-Hack-AskLeo",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "November 2025",
            "technologies": [
                { "name": "React", "description": "Frontend-UI-Framework" },
                { "name": "Vite", "description": "Build-Tool & Dev-Server" },
                { "name": "Recharts", "description": "Datenvisualisierungsdiagramme" },
                { "name": "CSS", "description": "Styling" },
                { "name": "Python", "description": "Backend-Programmiersprache" },
                { "name": "FastAPI", "description": "REST-API-Framework" },
                { "name": "Uvicorn", "description": "ASGI-Server" },
                { "name": "LangChain", "description": "LLM-Orchestrierungsframework" },
                { "name": "LangGraph", "description": "Multi-Agenten-Workflow-Engine" },
                { "name": "OpenAI GPT-4", "description": "KI-Chat & Reasoning" },
                { "name": "OpenAI Whisper", "description": "Sprach-zu-Text" },
                { "name": "ElevenLabs", "description": "Text-zu-Sprache" },
                { "name": "Gmail API", "description": "E-Mail-Automatisierung" },
                { "name": "Google Calendar API", "description": "Meeting-Planung" },
                { "name": "Pandas", "description": "Datenverarbeitung" },
                { "name": "DuckDB", "description": "Eingebettete Analytics-Datenbank" },
                { "name": "Tavily", "description": "Web-Such-API" },
                { "name": "MCP", "description": "Tool-Integrationsprotokoll" }
            ],
            "detailedDescription": "<p><strong>AskLeo</strong> ist ein intelligenter KI-Verhandlungsassistent, der für den Start Munich Hackathon entwickelt wurde. Er automatisiert Geschäftsverhandlungen mit Lieferanten, verwaltet Kommunikation über E-Mail und Kalender und bietet eine sprachaktivierte Schnittstelle für nahtlose Benutzerinteraktion.</p><ul><li><strong>Automatisierte Verhandlung:</strong> KI-Agenten verhandeln mit Lieferanten unter Verwendung strategischer Gesprächstaktiken</li><li><strong>Multi-Agenten-Kommunikation:</strong> Zwei KI-Agenten können automatisch miteinander verhandeln</li><li><strong>Sprachschnittstelle:</strong> Sprechen Sie mit der KI über OpenAI Whisper und hören Sie Antworten über ElevenLabs</li><li><strong>E-Mail-Integration:</strong> Sendet Bestätigungs-E-Mails nach erfolgreichen Geschäften über Gmail API</li><li><strong>Kalender-Planung:</strong> Plant automatisch Follow-up-Meetings über Google Calendar</li><li><strong>Produktwissen:</strong> Integrierter Produktkatalog für intelligente Empfehlungen</li></ul>"
        },
        {
            "id": 10,
            "title": "Slug Flow Crystallization",
            "description": "Datenbasierte Modellierung der Slug-Flow-Kristallisation mit Unsicherheitsquantifizierung",
            "category": "agentic-llm",
            "images": [
                "/images/project/Slug_Flow_Crystallization1.jpeg"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/MLME_SFC_13",
            "appLink": "",
            "purpose": "MLME-Projekt",
            "duration": "2 Monate",
            "date": "Juli 2025",
            "technologies": [
                "NARX",
                "CQR",
                "Tensorflow",
                "Datenvorverarbeitung",
                "Clustering",
                "Zeitreihen"
            ],
            "detailedDescription": "<h1>Datenbasierte Modellierung der Slug-Flow-Kristallisation mit Unsicherheitsquantifizierung</h1><p><strong>Autoren:</strong></p><ul><li>Shibin Thomas Stanley Paul - 259782</li><li>Aadhithya Krishnakumar - 258741</li><li>Nishitkumar Karkar - 257529</li><li>Sankar Santhosh Nair - 258852</li></ul><h2>Zusammenfassung</h2><p>Dieser Bericht stellt ein Machine-Learning-Framework zur Modellierung von Slug-Flow-Kristallisationsprozessen mit Unsicherheitsquantifizierung vor. Der Ansatz kombiniert drei Kernkomponenten:<ul><li>Unüberwachtes Clustering zur Erkennung von Betriebsregimen</li><li>Nichtlineare autoregressive Modelle mit exogenen Eingaben (NARX) neuronale Netze für dynamische Modellierung</li><li>Konformierte Quantilsregression (CQR) zur Bereitstellung zuverlässiger Vorhersageintervalle</li></ul>Die Ergebnisse zeigen eine genaue Regimetrennung, starke Modellgeneralisierung und kalibrierte Unsicherheitsschätzungen, was eine robuste Steuerung in pharmazeutischen Kristallisationsanwendungen erleichtert.</p><h2>I. Einführung</h2><p>Slug Flow Crystallization (SFC) wird in der pharmazeutischen Herstellung häufig verwendet, da es konsistente Partikelgrößen erzeugen kann. Herausforderungen entstehen jedoch aufgrund der dynamischen und nichtlinearen Natur der Kristallisation, verstärkt durch Rauschen in Partikelgrößenmessungen wie d10, d50 und d90.</p><h2>II. Datenanalyse und Clustering</h2><h3>A. Datenvorverarbeitung und Qualitätsbewertung</h3><p>Der Datensatz umfasst 98 Zeitreihendateien mit Prozessvariablenmessungen. Sieben Dateien mit abnormalen Bereichen in Partikelgrößenwerten wurden ausgeschlossen. Für die verbleibenden 91 Dateien:</p><ul><li>Duplikate und leere Einträge wurden entfernt</li><li>Ausreißer wurden mit benutzerdefinierten Schwellenwerten und Interquartilsabstand (IQR) Methoden gefiltert</li><li>IQR-basierte Filterung wurde aufgrund besserer Robustheit ausgewählt</li></ul><h3>B. Clustering-Analyse und Regimeidentifikation</h3><p>K-Means-Clustering mit k gleich 2 identifizierte zwei Regime. Metriken: Silhouette Score - 0,389, Calinski-Harabasz Score - 23,805, Davies-Bouldin Score - 1,459.</p><h2>III. NARX-Modellentwicklung</h2><p>NARX-Modelle wurden separat für jeden Cluster entwickelt. Die Modelle verwenden tiefe Feedforward-Netze mit sechs versteckten Schichten: 1024 bis 768 bis 512 bis 256 bis 128 bis 6. Aktivierung: SELU. Regularisierung: Dropout von 0,4 bis 0,2 und L2-Strafe.</p><h2>IV. Unsicherheitsquantifizierung</h2><p>Konformierte Quantilsregression mit 90% Abdeckung validiert für alle Variablen.</p><h2>V. Ergebnisse</h2><p>Die Unsicherheitsabdeckung betrug durchschnittlich 99,9% für geschlossene Schleifen und 97,2% für offene Schleifen, was die Zuverlässigkeit für den Einsatz in der Praxis bestätigt.</p><h2>VI. Fazit</h2><p>Das vorgeschlagene Framework integriert erfolgreich unüberwachtes Clustering, tiefe zeitliche Modellierung und prädiktive Unsicherheitsquantifizierung. Es erreicht starke Generalisierung, zuverlässige Intervallschätzungen und operative Regimetrennung, was es für die Echtzeitprozesssteuerung in der pharmazeutischen Kristallisation geeignet macht.</p>"
        },
        {
            "id": 9,
            "title": "Langgraph Core",
            "description": "Open-Source LangGraph-Implementierungsmuster und Beispiele",
            "category": "agentic-llm",
            "images": [
                "/images/project/Langgraph-Core1.jpeg"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/Langgraph-Core",
            "appLink": "",
            "purpose": "Open Source Projekt",
            "duration": "1 Monat",
            "date": "Mai 2025",
            "technologies": [
                "Open-AI",
                "Groq",
                "Gemini",
                "Ollama",
                "LLM",
                "LangGraph",
                "Streamlit"
            ],
            "detailedDescription": "<h2>LangGraph Core</h2><p>Ein umfassendes Open-Source-Projekt, das LangGraph-Implementierungsmuster mit mehreren LLM-Anbietern demonstriert.</p><h3>Funktionen</h3><ul><li>Multi-Provider-LLM-Unterstützung (OpenAI, Groq, Gemini, Ollama)</li><li>Graph-basierte Agenten-Workflows</li><li>Streamlit-UI für interaktive Demos</li><li>Bildungsbeispiele und Dokumentation</li><li>Produktionsreife Muster zum Erstellen von agentischen Anwendungen</li></ul>"
        },
        {
            "id": 8,
            "title": "Munich Sushi Chatbot",
            "description": "KI-Chatbot zum Finden von Sushi-Restaurants in München mit Parkunterstützung",
            "category": "agentic-llm",
            "images": [
                "/images/project/Munich-Sushi1.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/8AhdfVI-oU8?si=_zJ6zAP9A762ZIFO",
            "github": "https://github.com/sshibinthomass/Munich-sushi-Chatbot",
            "appLink": "",
            "purpose": "Persönliches Projekt",
            "duration": "2 Wochen",
            "date": "Juni 2025",
            "technologies": [
                "Open-AI",
                "LLM",
                "RAG",
                "LangGraph",
                "Streamlit",
                "ChromaDB",
                "MCP",
                "Google Maps",
                "Web RAG"
            ],
            "detailedDescription": "<h2>Munich Sushi Chatbot</h2><p>Ein KI-gestützter Chatbot, der Benutzern hilft, Sushi-Restaurants in München mit integrierter Parkunterstützung zu entdecken.</p><h3>Funktionen</h3><ul><li><strong>Sushi-Restaurant-Entdeckung:</strong> Finden Sie die besten Sushi-Plätze basierend auf Präferenzen, Bewertungen und Standort</li><li><strong>Parkunterstützung:</strong> Erhalten Sie Informationen zu nahegelegenen Parkplätzen und Verfügbarkeit</li><li><strong>Kontextuelle Informationen:</strong> Bewertungen, Öffnungszeiten, Wegbeschreibungen und mehr</li></ul><h3>Technologie-Stack</h3><ul><li><strong>LangGraph:</strong> Für Workflow-Orchestrierung und Agenten-Logik</li><li><strong>ChromaDB:</strong> Vektorspeicher für semantische Suche</li><li><strong>MCP (Model Context Protocol):</strong> Modulare Tool-Server</li><li><strong>Google Maps API:</strong> Standort- und Parkdaten</li><li><strong>Streamlit:</strong> Benutzeroberfläche</li><li><strong>OpenAI:</strong> Sprachmodell-Backbone</li></ul>"
        },
        {
            "id": 6,
            "title": "NaviBot",
            "description": "DRO-CO Bot - KI-gesteuerter humanoider Roboter für COVID SOP Compliance",
            "category": "robotics-iot",
            "images": [
                "/images/project/NaviBot1.jpeg",
                "/images/project/NaviBot2.jpeg",
                "/images/project/NaviBot3.jpeg",
                "/images/project/NaviBot4.jpeg",
                "/images/project/NaviBot5.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/QqrCg2vfLW0",
            "github": "",
            "appLink": "",
            "purpose": "College Abschlussprojekt",
            "duration": "1 Jahr",
            "date": "1. März 2022",
            "technologies": [
                "Deep Learning",
                "Machine Learning",
                "Flask",
                "Robotik",
                "Django"
            ],
            "detailedDescription": "<h3>Finanzierung & Anerkennung</h3><p>  Dieses Projekt wurde offiziell  <strong>unter dem Student Projects Scheme (SPS)</strong> vom  <strong>Tamil Nadu State Council for Science and Technology (TANSCST)</strong>, einer Initiative der Regierung von Tamil Nadu, während des akademischen Jahres  2021–2022 <strong>finanziert</strong>.</p><p>  Das <strong>TANSCST Student Projects Scheme</strong> ist ein wettbewerbsorientiertes Finanzierungsprogramm, das innovative und sozial wirkungsvolle Abschlussprojekte von Studenten in Wissenschaft, Ingenieurwesen und Technologie unterstützt.</p><h3>Problemstellung</h3><p>  Als Reaktion auf die COVID-19-Pandemie bestand ein dringender Bedarf an  berührungslosen Systemen zur Durchsetzung von Standardarbeitsverfahren (SOPs) wie  Temperaturprüfungen, Masken-Compliance und Anwesenheit in öffentlichen Umgebungen.</p><h3>Projektzusammenfassung</h3><p>  Ich konzipierte, entwarf, programmierte und fertigte einen humanoiden Roboter namens  <strong>DRO-CO Bot</strong>, einen KI-gestützten, IoT-integrierten Roboterassistenten.  Er kann Gesichtsmasken erkennen, Temperatur ohne Kontakt messen, Gesichter  zur automatischen Anwesenheitserfassung erkennen und mit Benutzern über Spracherkennung und  KI-gesteuerte Antworten interagieren.</p><h3>Funktionen und Fähigkeiten</h3><ul>  <li>Gesichtsmaskenerkennung mit TensorFlow und MobileNetV2</li>  <li>Echtzeit-Gesichtserkennung mit OpenCV und face_recognition-Bibliothek</li>  <li>Berührungslose Temperaturmessung mit MLX90614 IR-Sensor</li>  <li>Spracherkennung und Sprachantwort mit Python, pyttsx3 und Google Speech API</li>  <li>KI-gestützter Assistent mit Wikipedia, WolframAlpha und OpenWeather-Integrationen</li>  <li>WhatsApp-Automatisierung über Selenium für Live-Berichterstattung und Benachrichtigungen</li>  <li>Servomotor-basierter Roboterarm mit 3 DOF, gesteuert von Arduino</li>  <li>Ultraschall-basierte Objekterkennung und Menschenmengenüberwachung</li>  <li>Echtzeit-Anwesenheits- und Temperaturdatenprotokollierung</li></ul><h3>Technische Umsetzung</h3><ul>  <li>Entwicklung von Vorwärts- und Rückwärtskinematik für den Roboterarm mit D-H-Parametern</li>  <li>Berechnung von Drehmoment, Spannung, Dehnung, Knicklast für Roboter-Gelenke mit PLA-Strukturmaterial</li>  <li>Entwurf und 3D-Druck aller mechanischen Komponenten mit Fusion 360 und PLA-Filament</li>  <li>Etablierung von I2C-Kommunikation zwischen Raspberry Pi und Arduino zur Sensorsteuerung</li>  <li>Verwendung von Servomotoren (MG996R, RDS3115MG) zur Gelenksteuerung mit PID-basierter Positionsrückmeldung</li></ul><h3>Ergebnis</h3><ul>  <li>Erfolgreiche Fertigung und Tests eines voll funktionsfähigen autonomen COVID-19 SOP-Durchsetzungsroboters</li>  <li>Gesichtserkennung und Anwesenheitsaufzeichnung mit >95% Genauigkeit</li>  <li>Echtzeit-Erkennung von Maskenverstößen und Benachrichtigung von Benutzern über WhatsApp</li>  <li>Erfolgreich in einer Live-Industrieumgebung getestet</li></ul><h3>Projektbudget</h3><p>Gesamtkosten: ₹28.601 INR (Optimiert durch Open-Source-Tools und erschwingliche Komponenten)</p>"
        },
        {
            "id": 4,
            "title": "ARcadium",
            "description": "IOTAR-Anwendung - AR und IoT für verbessertes Lernen",
            "category": "web-app",
            "images": [
                "/images/project/ARcadium1.jpeg",
                "/images/project/ARcadium2.jpeg",
                "/images/project/ARcadium3.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/KQdLGSpzPxI",
            "github": "",
            "appLink": "",
            "purpose": "NSTF Codissia",
            "duration": "2 Jahre",
            "date": "4. März 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Augmented Reality"
            ],
            "detailedDescription": "<p align=\"justify\">&emsp;Augmented Reality (AR) ist eine Technologie, die digitale Informationen wie Sounds, Videos und Grafiken über die reale Umgebung legt. AR kann das Lernerlebnis verbessern, indem es interaktive und immersive Inhalte bereitstellt, die die Motivation, Aufmerksamkeit und das Verständnis der Lernenden anregen können. Internet of Things (IoT) ist eine Technologie, die physische Geräte wie Sensoren, Kameras und Aktuatoren mit dem Internet verbindet und Datenübertragung und -synchronisierung ermöglicht.<br><br>\n\n    &emsp;IOTAR ist ein Begriff, der AR und IoT kombiniert, um ein neuartiges Lernparadigma zu schaffen, das die Vorteile beider Technologien nutzt. IOTAR kann Lernenden kontextualisierte und personalisierte Lerninhalte bereitstellen, die auf ihrem Standort, ihren Präferenzen und ihrer Leistung basieren.<br><br>\n\n<b>Unsere Anwendung wurde mit AR für Mitarbeiter- und Studentenlernen mit IOTAR entwickelt. Unsere Anwendung hat die folgenden Funktionen und Vorteile:</b>\n<ul>\n<li>Sie verwendet AR, um 3D-Modelle von Objekten oder Konzepten anzuzeigen, die für die Lernziele relevant sind, wie Anatomie, Chemie, Physik oder Ingenieurwesen. Lernende können die Modelle aus verschiedenen Blickwinkeln und Perspektiven erkunden, hinein- und herauszoomen und sie drehen.</li>\n<li>Sie verwendet IoT, um Daten von Sensoren oder Geräten zu sammeln, um den Schwierigkeitsgrad, das Feedback oder den Inhalt der Lernaktivitäten entsprechend den Bedürfnissen und Präferenzen der Lernenden anzupassen.</li>\n<li>Sie verwendet AR, um gamifizierte Lernerfahrungen zu schaffen, die Lernende mit Punkten, Abzeichen, Bestenlisten oder Quests motivieren und herausfordern können.</li>\n<li>Sie verwendet IoT, um Zusammenarbeit und Kommunikation zwischen Lernenden zu ermöglichen, die sich an verschiedenen Orten befinden.</li>\n<li>Sie verwendet AR, um ein magisches Gefühl zu erzeugen, dass ein 3D-Objekt über der physischen Welt erscheint.</li>\n</ul><br>\n\n<b>Unsere Anwendung kann für verschiedene Zwecke und Kontexte verwendet werden, wie z.B.:</b>\n<ul>\n<li>Mitarbeiterschulung: Unsere Anwendung kann Mitarbeitern helfen, neue Fähigkeiten zu erlernen oder ihr Wissen auf unterhaltsame und ansprechende Weise zu aktualisieren.</li>\n<li>Studentenausbildung: Unsere Anwendung kann Studenten helfen, komplexe oder abstrakte Konzepte auf visuelle und interaktive Weise zu erlernen.</li>\n<li>Lebenslanges Lernen: Unsere Anwendung kann jedem helfen, der etwas Neues lernen oder seine Interessen auf flexible und bequeme Weise verfolgen möchte.</li>\n</ul>\n</p>"
        },
        {
            "id": 3,
            "title": "SubMerge",
            "description": "VR Unterwasser-Museum - Virtuelle Realität Unterwassererlebnis",
            "category": "web-app",
            "images": [
                "/images/project/SubMerge1.jpeg",
                "/images/project/SubMerge2.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/9ubWJePQCwg",
            "github": "",
            "appLink": "https://drive.google.com/file/d/1SkCRXHEn5xs_H8E9z1KcGtNdg5EASb57/view?usp=drive_link",
            "purpose": "SIH (Software-Edition)",
            "duration": "2 Wochen",
            "date": "6. März 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Virtual Reality"
            ],
            "detailedDescription": "<h1>VR Unterwassererlebnis - Projektdokumentation</h1><h2>Überblick</h2><p>  Ich entwickelte eine immersive Virtual Reality (VR) Anwendung für Android  Geräte mit Unity und Google VR. Diese Anwendung bietet Benutzern ein  interaktives Unterwassererlebnis und ermöglicht es ihnen, vier einzigartige  Umgebungen zu erkunden: Tower, Ship, Dance und Ride. Der Benutzer interagiert mit der  virtuellen Welt durch intuitive blickbasierte Navigation.</p><h2>Hauptmenü und Navigation</h2><p>  Beim Starten der Anwendung wird das Unity-Logo angezeigt. Nach dem Laden wird der Benutzer mit einem Hauptmenü begrüßt,  das die folgenden Optionen bietet:</p><ul>  <li>Tower</li>  <li>Dance</li>  <li>Ship</li>  <li>Ride</li></ul><p>  Das Menü wird mit blickbasierter Eingabe gesteuert. Benutzer schauen einfach auf eine der  Menüoptionen, um eine Auswahl zu treffen.</p><h2>Szenen und Funktionen</h2><h3>Tower-Bereich</h3><p>  Die Auswahl der Option 'Tower' versetzt den Benutzer in eine ruhige Unterwasser  Umgebung auf dem Meeresboden. Die Szene enthält:</p><ul>  <li>Blaue Haie, die durch die Szene schwimmen.</li>  <li>Eine zentrale turmartige Struktur, die architektonische Tiefe bietet.</li>  <li>Rosa und hellblaue Meerestiere, die lebendiges Meeresleben hinzufügen.</li>  <li>Realistische Meeresbodendetails wie Felsen, Seetang und Meeresflora.</li>  <li>Dunkler gefärbte Haie und weiße Wale, die durch das Wasser gleiten.</li>  <li>    Eine leuchtende grüne Kugel, die in der Nähe des Meeresbodens positioniert ist, um Neugier zu wecken.  </li></ul><h3>Ship-Bereich</h3><p>  Die 'Ship' Umgebung zeigt ein großes, teilweise versunkenes Schiff, das aus  verschiedenen Blickwinkeln betrachtet wird, während die Kamera dynamisch schwenkt.</p><h3>Dance-Bereich</h3><p>  Im 'Dance' Bereich habe ich eine choreografierte Sequenz erstellt, in der Meerestiere  sich synchron bewegen und einer Tanzaufführung ähneln.</p><h3>Ride-Bereich</h3><p>  Die Auswahl von 'Ride' bietet Benutzern eine geführte bootähnliche Reise durch die Unterwasserwelt.</p><h2>Technologie-Stack</h2><ul>  <li>    <strong>Unity:</strong> Spiel-Engine, die für die Entwicklung des VR-Erlebnisses verwendet wird.  </li>  <li>    <strong>Google VR SDK:</strong> Integriert zur Aktivierung von VR-Unterstützung auf Android-Geräten.  </li>  <li>    <strong>Blender:</strong> Verwendet zur Modellierung und Animation von 3D-Meereslebewesen.  </li>  <li>    <strong>C#:</strong> Programmiersprache, die innerhalb von Unity für Scripting verwendet wird.  </li></ul>"
        },
        {
            "id": 2,
            "title": "Spikora",
            "description": "RosaryPlantHouse.com – E-Commerce-Webanwendung für Pflanzenliebhaber",
            "category": "web-app",
            "images": [
                "/images/project/Spikora1.jpeg",
                "/images/project/Spikora2.jpeg"
            ],
            "youtubeLink": "",
            "github": "",
            "appLink": "https://www.rosaryplanthouse.com",
            "purpose": "Rosary Plant House",
            "duration": "2 Wochen",
            "date": "7. März 2022",
            "technologies": [
                "HTML",
                "CSS",
                "JavaScript",
                "E-Commerce"
            ],
            "detailedDescription": "<h2>RosaryPlantHouse.com – E-Commerce-Webanwendung</h2><p>  Ich entwickelte <strong>RosaryPlantHouse.com</strong>, eine statische E-Commerce  Website, die speziell für Pflanzenliebhaber entwickelt wurde. Dieses Projekt stellt eine  vollständige End-to-End-Lösung dar, die ich erstellt habe und die alles von  Architektur und Datenverwaltung bis hin zu Benutzererfahrung und operativem Design umfasst.  Die Plattform wurde für Leistung, Einfachheit und minimalen operativen  Overhead entwickelt und zeigt meine Fähigkeiten in kreativer Problemlösung, Front-End  Engineering und strategischem Produktdenken.</p><h3><strong>Executive Summary</strong></h3><p>  Die Rosary Plant House Anwendung wurde vollständig als statische Website  entwickelt, wobei clientseitiges JavaScript die gesamte Interaktivität antreibt. Dies umfasst ein  ausgeklügeltes Produktkatalog, Warenkorbverwaltungssystem und einen neuartigen  WhatsApp-basierten Checkout-Mechanismus, den ich als innovative Alternative zur  traditionellen E-Commerce-Infrastruktur entwickelt habe.</p><h3><strong>Systemarchitektur und Technologie-Stack</strong></h3><h4><strong>'Static-First' E-Commerce-Engine</strong></h4><p>  Ich baute die Website mit einem Jamstack-Ansatz, der vorgefertigte HTML-Seiten  wie <code>catalogue.html</code> und <code>restocked.html</code> für  Leistung und Sicherheit liefert. Die gesamte Warenkorb-, Filter- und UI-Logik wird von  clientseitigem JavaScript angetrieben, wodurch kein Backend-Server erforderlich ist.</p><h4><strong>Leistung, Sicherheit und operative Effizienz</strong></h4><ul>  <li><strong>Leistung:</strong> Gehostet auf einem CDN für schnelle Ladezeiten.</li>  <li><strong>Sicherheit:</strong> Kein Backend = minimale Angriffsfläche.</li>  <li>    <strong>Wartung:</strong> Kein Server oder Datenbank zu warten,    was die Kosten erheblich senkt.  </li></ul><h4><strong>Technologie-Stack</strong></h4><ul>  <li><strong>HTML5, CSS:</strong> Für Struktur und responsives Design.</li>  <li>    <strong>JavaScript:</strong> Für Warenkorb, Filterung und Checkout-Integration.  </li>  <li>    <strong>Web Storage API (localStorage):</strong> Zum Persistieren des Warenkorbzustands    über Sitzungen hinweg.  </li></ul><h4><strong>WhatsApp Checkout – 'Conversational Commerce'</strong></h4><p>  Ich entwickelte einen einzigartigen clientseitigen Checkout, der die WhatsApp API verwendet. Beim  Klicken auf 'Bestellung aufgeben':</p><ol>  <li>JavaScript kompiliert den Warenkorb in eine formatierte Nachricht.</li>  <li>    Es URL-kodiert die Nachricht und leitet den Benutzer über einen    <code>https://wa.me</code> Link zu WhatsApp weiter.  </li>  <li>    Das Unternehmen erhält die Nachricht direkt und bestätigt die Bestellung manuell.  </li></ol><h3><strong>Fazit</strong></h3><p>  Dieses Projekt ist ein vollständiges, reales Beispiel für intelligentes Design unter  engen Einschränkungen. Es zeigt meine Full-Stack-Problemlösungsfähigkeit, meine  Kompetenz in der statischen Webentwicklung und meine kreative Nutzung bestehender Tools  (wie WhatsApp), um Geschäftsherausforderungen zu lösen.</p>"
        }
    ]
}