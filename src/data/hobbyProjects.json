{
    "en": [
        {
            "id": 13,
            "title": "MediMind",
            "description": "An AI-powered personal medical assistant that helps users track health metrics, manage medical information, and receive intelligent health guidance. Features dual modes for patients and healthcare providers, real-time health dashboard, and multi-LLM support",
            "category": "agentic-llm",
            "images": [
                "/images/project/mediMind.jpg"
            ],
            "youtubeLink": "https://youtu.be/ALTnhbkpddc",
            "github": "https://github.com/sshibinthomass/nucleate-hack-medi-minds",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "November 2025",
            "technologies": [
                { "name": "React", "description": "Frontend library for building the interactive health dashboard UI" },
                { "name": "Vite", "description": "Fast build tool and development server for the React frontend" },
                { "name": "FastAPI", "description": "High-performance Python backend framework for REST API endpoints" },
                { "name": "LangChain", "description": "Framework for building AI-powered applications with LLM orchestration" },
                { "name": "LangGraph", "description": "Library for creating stateful, multi-actor AI agent workflows" },
                { "name": "Groq", "description": "LLM provider integration for ultra-fast AI inference" },
                { "name": "OpenAI", "description": "GPT model integration for intelligent medical assistance" },
                { "name": "Google Gemini", "description": "Google's multimodal AI model for conversational intelligence" },
                { "name": "Ollama", "description": "Local LLM support for running AI models offline" },
                { "name": "MCP (Model Context Protocol)", "description": "Protocol for integrating external tools and data sources with AI agents" },
                { "name": "Python", "description": "Backend programming language powering the API and AI logic" },
                { "name": "Pandas", "description": "Data analysis library for health metrics processing" },
                { "name": "Plotly", "description": "Interactive visualization library for health data charts" },
                { "name": "scikit-learn", "description": "Machine learning library for health forecasting and predictions" },
                { "name": "DuckDB", "description": "Embedded analytics database for efficient data querying" },
                { "name": "Gmail API", "description": "Email integration for sending medical-related communications" }
            ],
            "detailedDescription": "<p><strong>Medi-Mind</strong> is a comprehensive AI-powered healthcare management platform built with React and FastAPI that bridges the gap between patients and healthcare providers. It features a <strong>personal medical assistant</strong> with real-time health tracking (steps, calories, heart rate, blood oxygen, water intake, mood, sleep, energy levels), interactive health metric visualization with Plotly charts, and intelligent AI-powered medical guidance. The platform supports <strong>multiple LLM providers</strong> including OpenAI GPT, Google Gemini, Groq, and local Ollama models, enabling flexible and context-aware medical conversations. It offers <strong>dual use cases</strong>: a Medical Assistant mode for patients to track and understand their health, and a Doctor Assistant mode for healthcare professionals with patient management, analytics, and age group demographics. Key features include <strong>MCP (Model Context Protocol)</strong> integration for external tool connectivity, <strong>Gmail integration</strong> for medical communications, weather and date context awareness, health alerts when metrics fall below recommended levels, and <strong>machine learning-based health forecasting</strong> using scikit-learn and statsmodels. Built using LangChain and LangGraph for sophisticated AI agent workflows, the system provides empathetic, professional, and data-driven health insights while maintaining a modern, responsive UI with animated health widgets and real-time data synchronization.</p>"
        },
            {
            "id": 12,
            "title": "GenDesign",
            "description": "GenDesign is an intelligent structural engineering assistant that helps engineers design optimal beams through natural conversation in English and German. It combines advanced AI orchestration using LangGraph, physics-based calculations, machine learning models, and interactive 3D visualization to provide comprehensive beam analysis and optimization.",
            "category": "agentic-llm",
            "images": [
                "/images/project/genDesign.jpg"
            ],
            "youtubeLink": "https://youtu.be/jf_8_DkVa8s",
            "github": "https://github.com/sshibinthomass/BKW-Design-Agent",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "October 2025",
            "technologies": [
                    { "name": "Python", "description": "Backend language for Flask app and AI orchestration" },
                { "name": "Flask", "description": "Web framework for REST API and server logic" },
                { "name": "Anthropic Claude", "description": "LLM for natural language conversation" },
                { "name": "Google Gemini", "description": "AI model for enhanced conversations" },
                { "name": "LangGraph", "description": "Agentic AI orchestration framework" },
                { "name": "SciPy", "description": "Scientific computing for beam optimization" },
                { "name": "scikit-learn", "description": "ML library for deflection prediction" },
                { "name": "Pandas", "description": "Data manipulation and CSV handling" },
                { "name": "NumPy", "description": "Numerical computing for calculations" },
                { "name": "Plotly", "description": "Interactive 3D visualization library" },
                { "name": "MCP Tools", "description": "Model Context Protocol integration" },
                { "name": "JavaScript", "description": "Frontend scripting and UI interactions" },
                { "name": "HTML5", "description": "Semantic markup and file uploads" },
                { "name": "CSS3", "description": "Modern styling with Flexbox and Grid" }
            ],
            "detailedDescription": "<p><strong>GenDesign</strong> is an AI-powered structural engineering assistant that enables natural language beam design in <em>English and German</em>, combining <strong>LangGraph agentic AI orchestration</strong>, <strong>Anthropic Claude LLM</strong> for conversation management, <strong>Random Forest ML models</strong> for deflection prediction, <strong>SciPy-based optimization</strong> for volume minimization, and <strong>Plotly 3D visualization</strong> for interactive beam rendering, with support for <em>Steel (IPE profiles)</em>, <em>Wood</em>, and <em>Concrete</em> materials, plus intelligent task management with vacation approval logic and a historical database of 3000+ successful designs for pattern recognition and recommendations.</p>"
        },
        {
            "id": 11,
            "title": "AskLeo",
            "description": "AskLeo is an AI-powered negotiation assistant that automates business negotiations with vendors using multi-agent conversations, voice interface, and integrated email/calendar automation.",
            "category": "agentic-llm",
            "images": [
                "/images/project/askLeo.jpg"
            ],
            "youtubeLink": "https://youtu.be/YjnY0FsknZA",
            "github": "https://github.com/sshibinthomass/Start-Munich-Hack-AskLeo",
            "appLink": "",
            "purpose": "Hackathon",
            "duration": "",
            "date": "November 2025",
            "technologies": [
                { "name": "React", "description": "Frontend UI framework" },
                { "name": "Vite", "description": "Build tool & dev server" },
                { "name": "Recharts", "description": "Data visualization charts" },
                { "name": "CSS", "description": "Styling" },
                { "name": "Python", "description": "Backend programming language" },
                { "name": "FastAPI", "description": "REST API framework" },
                { "name": "Uvicorn", "description": "ASGI server" },
                { "name": "LangChain", "description": "LLM orchestration framework" },
                { "name": "LangGraph", "description": "Multi-agent workflow engine" },
                { "name": "OpenAI GPT-4", "description": "AI chat & reasoning" },
                { "name": "OpenAI Whisper", "description": "Speech-to-text" },
                { "name": "ElevenLabs", "description": "Text-to-speech" },
                { "name": "Gmail API", "description": "Email automation" },
                { "name": "Google Calendar API", "description": "Meeting scheduling" },
                { "name": "Pandas", "description": "Data processing" },
                { "name": "DuckDB", "description": "Embedded analytics database" },
                { "name": "Tavily", "description": "Web search API" },
                { "name": "MCP", "description": "Tool integration protocol" }
            ],
            "detailedDescription": "<p><strong>AskLeo</strong> is an intelligent AI negotiation assistant built for the Start Munich Hackathon. It automates business negotiations with vendors, manages communications via email and calendar, and provides a voice-enabled interface for seamless user interaction.</p><ul><li><strong>Automated Negotiation:</strong> AI agents negotiate with vendors using strategic conversation tactics</li><li><strong>Multi-Agent Communication:</strong> Two AI agents can negotiate with each other automatically</li><li><strong>Voice Interface:</strong> Speak with the AI using OpenAI Whisper and hear responses via ElevenLabs</li><li><strong>Email Integration:</strong> Sends confirmation emails after successful deals via Gmail API</li><li><strong>Calendar Scheduling:</strong> Automatically schedules follow-up meetings via Google Calendar</li><li><strong>Product Knowledge:</strong> Integrated product catalog for intelligent recommendations</li></ul>"
        },
        {
            "id": 10,
            "title": "Slug Flow Crystallization",
            "description": "Data-based Modeling of Slug Flow Crystallization with Uncertainty Quantification",
            "category": "agentic-llm",
            "images": [
                "/images/project/Slug_Flow_Crystallization1.jpeg"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/MLME_SFC_13",
            "appLink": "",
            "purpose": "MLME Project",
            "duration": "2 months",
            "date": "July 2025",
            "technologies": [
                "NARX",
                "CQR",
                "Tensorflow",
                "Data Preprocessing",
                "Clustering",
                "Time Series"
            ],
            "detailedDescription": "<h1>Data-based Modeling of Slug Flow Crystallization with Uncertainty Quantification</h1><p><strong>Authors:</strong></p><ul><li>Shibin Thomas Stanley Paul - 259782</li><li>Aadhithya Krishnakumar - 258741</li><li>Nishitkumar Karkar - 257529</li><li>Sankar Santhosh Nair - 258852</li></ul><h2>Abstract</h2><p>This report presents a machine learning framework for modeling slug flow crystallization processes with uncertainty quantification. The approach combines three core components:<ul><li>Unsupervised clustering to detect operational regimes</li><li>Nonlinear Autoregressive with Exogenous Inputs (NARX) neural networks for dynamic modeling</li><li>Conformalized Quantile Regression (CQR) for providing reliable prediction intervals</li></ul>Results demonstrate accurate regime separation, strong model generalization, and calibrated uncertainty estimates, facilitating robust control in pharmaceutical crystallization applications.</p><h2>I. Introduction</h2><p>Slug Flow Crystallization (SFC) is widely used in pharmaceutical manufacturing for its ability to produce consistent particle sizes. However, challenges arise due to the dynamic and nonlinear nature of crystallization, compounded by noise in particle size measurements such as d10, d50, and d90.</p><h2>II. Data Analysis and Clustering</h2><h3>A. Data Preprocessing and Quality Assessment</h3><p>The dataset comprises 98 time series files with process variable measurements. Seven files containing abnormal ranges in particle size values were excluded. For the remaining 91 files:</p><ul><li>Duplicates and empty entries were removed</li><li>Outliers were filtered using custom thresholding and Interquartile Range (IQR) methods</li><li>IQR-based filtering was selected due to better robustness</li></ul><h3>B. Clustering Analysis and Regime Identification</h3><p>K-means clustering with k equal to 2 identified two regimes. Metrics: Silhouette Score - 0.389, Calinski-Harabasz Score - 23.805, Davies-Bouldin Score - 1.459.</p><h2>III. NARX Model Development</h2><p>NARX models were developed separately for each cluster. The models use deep feedforward networks with six hidden layers: 1024 to 768 to 512 to 256 to 128 to 6. Activation: SELU. Regularization: dropout from 0.4 to 0.2 and L2 penalty.</p><h2>IV. Uncertainty Quantification</h2><p>Conformalized Quantile Regression with 90% coverage validated across all variables.</p><h2>V. Results</h2><p>Uncertainty coverage averaged 99.9% for closed loop and 97.2% for open loop cases, confirming reliability for real-world deployment.</p><h2>VI. Conclusion</h2><p>The proposed framework successfully integrates unsupervised clustering, deep temporal modeling, and predictive uncertainty quantification. It achieves strong generalization, reliable interval estimates, and operational regime separation, making it suitable for real-time process control in pharmaceutical crystallization.</p>"
        },
        {
            "id": 9,
            "title": "Langgraph Core",
            "description": "Open-source LangGraph implementation patterns and examples",
            "category": "agentic-llm",
            "images": [
                "/images/project/Langgraph-Core1.jpeg"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/Langgraph-Core",
            "appLink": "",
            "purpose": "Open Source Project",
            "duration": "1 month",
            "date": "May 2025",
            "technologies": [
                "Open-AI",
                "Groq",
                "Gemini",
                "Ollama",
                "LLM",
                "LangGraph",
                "Streamlit"
            ],
            "detailedDescription": "<h2>LangGraph Core</h2><p>A comprehensive open-source project demonstrating LangGraph implementation patterns with multiple LLM providers.</p><h3>Features</h3><ul><li>Multi-provider LLM support (OpenAI, Groq, Gemini, Ollama)</li><li>Graph-based agent workflows</li><li>Streamlit UI for interactive demos</li><li>Educational examples and documentation</li><li>Production-ready patterns for building agentic applications</li></ul>"
        },
        {
            "id": 8,
            "title": "Munich Sushi Chatbot",
            "description": "AI chatbot for finding sushi restaurants in Munich with parking assistance",
            "category": "agentic-llm",
            "images": [
                "/images/project/Munich-Sushi1.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/8AhdfVI-oU8?si=_zJ6zAP9A762ZIFO",
            "github": "https://github.com/sshibinthomass/Munich-sushi-Chatbot",
            "appLink": "",
            "purpose": "Personal Project",
            "duration": "2 weeks",
            "date": "June 2025",
            "technologies": [
                "Open-AI",
                "LLM",
                "RAG",
                "LangGraph",
                "Streamlit",
                "ChromaDB",
                "MCP",
                "Google Maps",
                "Web RAG"
            ],
            "detailedDescription": "<h2>Munich Sushi Chatbot</h2><p>An AI-powered chatbot that helps users discover sushi restaurants in Munich with integrated parking assistance.</p><h3>Features</h3><ul><li><strong>Sushi Restaurant Discovery:</strong> Find the best sushi places based on preferences, ratings, and location</li><li><strong>Parking Assistance:</strong> Get nearby parking information and availability</li><li><strong>Contextual Information:</strong> Reviews, hours, directions, and more</li></ul><h3>Technology Stack</h3><ul><li><strong>LangGraph:</strong> For workflow orchestration and agent logic</li><li><strong>ChromaDB:</strong> Vector store for semantic search</li><li><strong>MCP (Model Context Protocol):</strong> Modular tool servers</li><li><strong>Google Maps API:</strong> Location and parking data</li><li><strong>Streamlit:</strong> User interface</li><li><strong>OpenAI:</strong> Language model backbone</li></ul>"
        },
        {
            "id": 6,
            "title": "NaviBot",
            "description": "DRO-CO Bot - AI-powered Humanoid Robot for COVID SOP Compliance",
            "category": "robotics-iot",
            "images": [
                "/images/project/NaviBot1.jpeg",
                "/images/project/NaviBot2.jpeg",
                "/images/project/NaviBot3.jpeg",
                "/images/project/NaviBot4.jpeg",
                "/images/project/NaviBot5.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/QqrCg2vfLW0",
            "github": "",
            "appLink": "",
            "purpose": "College Final Project",
            "duration": "1 Year",
            "date": "1 March 2022",
            "technologies": [
                "Deep Learning",
                "Machine Learning",
                "Flask",
                "Robotics",
                "Django"
            ],
            "detailedDescription": "<h3>Funding & Recognition</h3><p>  This project was officially  <strong>funded under the Student Projects Scheme (SPS)</strong> by the  <strong>Tamil Nadu State Council for Science and Technology (TANSCST)</strong>, an initiative under the Government of Tamil Nadu, during the academic year  2021–2022.</p><p>  The <strong>TANSCST Student Projects Scheme</strong> is a competitive funding  program that supports innovative and socially impactful final-year student  projects in science, engineering, and technology.</p><h3>Problem Statement</h3><p>  In response to the COVID-19 pandemic, there was an urgent requirement for  contactless systems to enforce Standard Operating Procedures (SOPs) like  temperature checks, mask compliance, and attendance in public environments.</p><h3>Project Summary</h3><p>  I conceptualized, designed, programmed, and fabricated a humanoid robot named  <strong>DRO-CO Bot</strong>, an AI-powered, IoT-integrated robotic assistant.  It can detect face masks, measure temperature without contact, recognize faces  for automatic attendance, and interact with users using speech recognition and  AI-driven responses.</p><h3>Features and Capabilities</h3><ul>  <li>Face mask detection using TensorFlow and MobileNetV2</li>  <li>Real-time face recognition using OpenCV and face_recognition library</li>  <li>Contactless temperature sensing using MLX90614 IR sensor</li>  <li>Speech recognition and voice response using Python, pyttsx3, and Google Speech API</li>  <li>AI-powered assistant with Wikipedia, WolframAlpha, and OpenWeather integrations</li>  <li>WhatsApp automation via Selenium for live reporting and alerts</li>  <li>Servo motor-based robotic arm with 3 DOF controlled by Arduino</li>  <li>Ultrasonic-based object detection and crowd monitoring</li>  <li>Real-time attendance and temperature data logging</li></ul><h3>Technical Implementation</h3><ul>  <li>Developed both forward and inverse kinematics for the robotic arm using D-H parameters</li>  <li>Calculated torque, stress, strain, buckling load for robot joints using PLA structural material</li>  <li>Designed and 3D printed all mechanical components using Fusion 360 and PLA filament</li>  <li>Established I2C communication between Raspberry Pi and Arduino for sensor control</li>  <li>Used servo motors (MG996R, RDS3115MG) for joint control with PID-based position feedback</li></ul><h3>Outcome</h3><ul>  <li>Successfully fabricated and tested a fully functional autonomous COVID-19 SOP enforcement robot</li>  <li>Recognized faces and recorded attendance with >95% accuracy</li>  <li>Detected mask violations in real-time and notified users via WhatsApp</li>  <li>Tested successfully in a live industrial environment</li></ul><h3>Project Budget</h3><p>Total Cost: ₹28,601 INR (Optimized through open-source tools and affordable components)</p>"
        },
        {
            "id": 4,
            "title": "ARcadium",
            "description": "IOTAR Application - AR and IoT for Enhanced Learning",
            "category": "web-app",
            "images": [
                "/images/project/ARcadium1.jpeg",
                "/images/project/ARcadium2.jpeg",
                "/images/project/ARcadium3.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/KQdLGSpzPxI",
            "github": "",
            "appLink": "",
            "purpose": "NSTF Codissia",
            "duration": "2 year",
            "date": "4 March 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Augmented Reality"
            ],
            "detailedDescription": "<p align=\"justify\">&emsp;Augmented reality (AR) is a technology that overlays digital information such as sounds, videos, and graphics on top of the real-world environment. AR can enhance the learning experience by providing interactive and immersive content that can stimulate learners' motivation, attention, and understanding. Internet of things (IoT) is a technology that connects physical devices, such as sensors, cameras, and actuators, to the internet and enables data transmission and synchronization.<br><br>\n\n    &emsp;IOTAR is a term that combines AR and IoT to create a novel learning paradigm that leverages the advantages of both technologies. IOTAR can provide learners with contextualized and personalized learning content that is based on their location, preferences, and performance.<br><br>\n\n<b>Our application is developed using AR for employee and student learning using IOTAR. Our application has the following features and benefits:</b>\n<ul>\n<li>It uses AR to display 3D models of objects or concepts that are relevant to the learning objectives, such as anatomy, chemistry, physics, or engineering. Learners can explore the models from different angles and perspectives, zoom in and out, and rotate them.</li>\n<li>It uses IoT to collect data from sensors or devices to adjust the difficulty level, feedback, or content of the learning activities according to the learners' needs and preferences.</li>\n<li>It uses AR to create gamified learning experiences that can motivate and challenge learners with points, badges, leaderboards, or quests.</li>\n<li>It uses IoT to enable collaboration and communication among learners who are located in different places.</li>\n<li>It uses AR to create a magical feeling of a 3D object appearing on top of the physical world.</li>\n</ul><br>\n\n<b>Our application can be used for various purposes and contexts, such as:</b>\n<ul>\n<li>Employee training: Our application can help employees learn new skills or update their knowledge in a fun and engaging way.</li>\n<li>Student education: Our application can help students learn complex or abstract concepts in a visual and interactive way.</li>\n<li>Lifelong learning: Our application can help anyone who wants to learn something new or pursue their interests in a flexible and convenient way.</li>\n</ul>\n</p>"
        },
        {
            "id": 3,
            "title": "SubMerge",
            "description": "Exploring the Aquatic Wonders - A Virtual Reality Underwater Museum",
            "category": "web-app",
            "images": [
                "/images/project/SubMerge1.jpeg",
                "/images/project/SubMerge2.jpeg"
            ],
            "youtubeLink": "https://www.youtube.com/embed/9ubWJePQCwg",
            "github": "",
            "appLink": "https://drive.google.com/file/d/1SkCRXHEn5xs_H8E9z1KcGtNdg5EASb57/view?usp=drive_link",
            "purpose": "SIH (Software edition)",
            "duration": "2 weeks",
            "date": "6 March 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Virtual Reality"
            ],
            "detailedDescription": "<h1>VR Underwater Experience - Project Documentation</h1><h2>Overview</h2><p>  I developed an immersive Virtual Reality (VR) application designed for Android  devices using Unity and Google VR. This application provides users with an  interactive underwater experience, enabling them to explore four unique  environments: Tower, Ship, Dance, and Ride. The user interacts with the  virtual world through intuitive gaze-based navigation.</p><h2>Main Menu and Navigation</h2><p>  Upon launching the application, the Unity logo is displayed. After loading, the user is greeted with a main menu  offering the following options:</p><ul>  <li>Tower</li>  <li>Dance</li>  <li>Ship</li>  <li>Ride</li></ul><p>  The menu is controlled using gaze-based input. Users simply look at one of the  menu options to make a selection.</p><h2>Scenes and Features</h2><h3>Tower Section</h3><p>  Selecting the 'Tower' option transports the user to a serene underwater  environment situated on the seabed. The scene includes:</p><ul>  <li>Blue sharks swimming across the scene.</li>  <li>A central tower-like structure providing architectural depth.</li>  <li>Pink and light blue aquatic creatures adding vibrant marine life.</li>  <li>Realistic seabed details such as rocks, seaweed, and marine flora.</li>  <li>Darker colored sharks and white whales gliding through the water.</li>  <li>    A glowing green orb positioned near the ocean floor to create intrigue.  </li></ul><h3>Ship Section</h3><p>  The 'Ship' environment features a large, partially submerged ship, viewed from  various angles as the camera pans dynamically.</p><h3>Dance Section</h3><p>  In the 'Dance' section, I created a choreographed sequence where marine  animals move in synchronization, resembling a dance performance.</p><h3>Ride Section</h3><p>  Choosing 'Ride' offers users a guided boat-like journey through the underwater  world.</p><h2>Technology Stack</h2><ul>  <li>    <strong>Unity:</strong> Game engine used for developing the VR experience.  </li>  <li>    <strong>Google VR SDK:</strong> Integrated for enabling VR support on Android devices.  </li>  <li>    <strong>Blender:</strong> Used to model and animate 3D marine life.  </li>  <li>    <strong>C#:</strong> Programming language used within Unity for scripting.  </li></ul>"
        },
        {
            "id": 2,
            "title": "Spikora",
            "description": "RosaryPlantHouse.com – E-commerce Web Application for Plant Lovers",
            "category": "web-app",
            "images": [
                "/images/project/Spikora1.jpeg",
                "/images/project/Spikora2.jpeg"
            ],
            "youtubeLink": "",
            "github": "",
            "appLink": "https://www.rosaryplanthouse.com",
            "purpose": "Rosary Plant House",
            "duration": "2 weeks",
            "date": "7 March 2022",
            "technologies": [
                "HTML",
                "CSS",
                "JavaScript",
                "Ecommerce"
            ],
            "detailedDescription": "<h2>RosaryPlantHouse.com – E-commerce Web Application</h2><p>  I developed <strong>RosaryPlantHouse.com</strong>, a static-first e-commerce  website specifically tailored for plant enthusiasts. This project represents a  complete end-to-end solution I created, encompassing everything from  architecture and data management to user experience and operational design.  The platform was designed for performance, simplicity, and minimal operational  overhead, and it showcases my skills in creative problem-solving, front-end  engineering, and strategic product thinking.</p><h3><strong>Executive Summary</strong></h3><p>  The Rosary Plant House application was engineered entirely as a static website  with client-side JavaScript powering all interactivity. This includes a  sophisticated product catalogue, cart management system, and a novel  WhatsApp-based checkout mechanism I designed as an innovative alternative to  traditional e-commerce infrastructure.</p><h3><strong>System Architecture and Technology Stack</strong></h3><h4><strong>'Static-First' E-Commerce Engine</strong></h4><p>  I built the site using a Jamstack approach, delivering pre-built HTML pages  such as <code>catalogue.html</code> and <code>restocked.html</code> for  performance and security. All cart, filtering, and UI logic is powered by  client-side JavaScript, removing the need for a backend server.</p><h4><strong>Performance, Security, and Operational Efficiency</strong></h4><ul>  <li><strong>Performance:</strong> Hosted on a CDN for fast load times.</li>  <li><strong>Security:</strong> No backend = minimal attack surface.</li>  <li>    <strong>Maintenance:</strong> No server or database to maintain,    dramatically lowering costs.  </li></ul><h4><strong>Technology Stack</strong></h4><ul>  <li><strong>HTML5, CSS:</strong> For structure and responsive design.</li>  <li>    <strong>JavaScript:</strong> For cart, filtering, and checkout integration.  </li>  <li>    <strong>Web Storage API (localStorage):</strong> To persist cart state    across sessions.  </li></ul><h4><strong>WhatsApp Checkout – 'Conversational Commerce'</strong></h4><p>  I built a unique client-side checkout that uses the WhatsApp API. Upon  clicking 'Place Order':</p><ol>  <li>JavaScript compiles the cart into a formatted message.</li>  <li>    It URL-encodes the message and redirects the user to WhatsApp via a    <code>https://wa.me</code> link.  </li>  <li>    The business receives the message directly and confirms the order manually.  </li></ol><h3><strong>Conclusion</strong></h3><p>  This project is a complete, real-world example of intelligent design under  tight constraints. It demonstrates my full-stack problem-solving ability, my  proficiency in static web development, and my creative use of existing tools  (like WhatsApp) to solve business challenges.</p>"
        }
    ],
    "de": [
        {
            "id": 10,
            "title": "Slug Flow Crystallization",
            "description": "Datenbasierte Modellierung der Slug-Flow-Kristallisation mit Unsicherheitsquantifizierung",
            "category": "agentic-llm",
            "images": [
                "/images/hobby-project.png"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/MLME_SFC_13",
            "appLink": "",
            "purpose": "MLME-Projekt",
            "duration": "2 Monate",
            "date": "Juli 2025",
            "technologies": [
                "NARX",
                "CQR",
                "Tensorflow",
                "Datenvorverarbeitung",
                "Clustering",
                "Zeitreihen"
            ],
            "detailedDescription": "<p>Machine-Learning-Framework für pharmazeutische Kristallisationsprozesse mit NARX-Modellen und konformer Vorhersage.</p>"
        },
        {
            "id": 9,
            "title": "Langgraph Core",
            "description": "Open-Source LangGraph-Implementierungsmuster und Beispiele",
            "category": "agentic-llm",
            "images": [
                "/images/hobby-project.png"
            ],
            "youtubeLink": "",
            "github": "https://github.com/sshibinthomass/Langgraph-Core",
            "appLink": "",
            "purpose": "Open Source Projekt",
            "duration": "1 Monat",
            "date": "Mai 2025",
            "technologies": [
                "Open-AI",
                "Groq",
                "Gemini",
                "Ollama",
                "LLM",
                "LangGraph",
                "Streamlit"
            ],
            "detailedDescription": "<p>Umfassendes Open-Source-Projekt mit LangGraph-Implementierungsmustern für mehrere LLM-Anbieter.</p>"
        },
        {
            "id": 8,
            "title": "Munich Sushi Chatbot",
            "description": "KI-Chatbot zum Finden von Sushi-Restaurants in München mit Parkunterstützung",
            "category": "agentic-llm",
            "images": [
                "/images/hobby-project.png"
            ],
            "youtubeLink": "https://www.youtube.com/embed/8AhdfVI-oU8?si=_zJ6zAP9A762ZIFO",
            "github": "https://github.com/sshibinthomass/Munich-sushi-Chatbot",
            "appLink": "",
            "purpose": "Persönliches Projekt",
            "duration": "2 Wochen",
            "date": "Juni 2025",
            "technologies": [
                "Open-AI",
                "LLM",
                "RAG",
                "LangGraph",
                "Streamlit",
                "ChromaDB",
                "MCP",
                "Google Maps",
                "Web RAG"
            ],
            "detailedDescription": "<p>KI-gesteuerter Chatbot für Sushi-Restaurant-Entdeckung in München mit Parkplatzunterstützung.</p>"
        },
        {
            "id": 6,
            "title": "NaviBot",
            "description": "DRO-CO Bot - KI-gesteuerter humanoider Roboter für COVID SOP Compliance",
            "category": "robotics-iot",
            "images": [
                "/images/hobby-project.png"
            ],
            "youtubeLink": "https://www.youtube.com/embed/QqrCg2vfLW0",
            "github": "",
            "appLink": "",
            "purpose": "College Abschlussprojekt",
            "duration": "1 Jahr",
            "date": "1. März 2022",
            "technologies": [
                "Deep Learning",
                "Machine Learning",
                "Flask",
                "Robotik",
                "Django"
            ],
            "detailedDescription": "<p>Von TANSCST finanzierter humanoider Roboter mit Gesichtserkennung, Temperaturmessung und Sprachassistent.</p>"
        },
        {
            "id": 4,
            "title": "ARcadium",
            "description": "IOTAR-Anwendung - AR und IoT für verbessertes Lernen",
            "category": "web-app",
            "images": [
                "/images/hobby-project.png"
            ],
            "youtubeLink": "https://www.youtube.com/embed/KQdLGSpzPxI",
            "github": "",
            "appLink": "",
            "purpose": "NSTF Codissia",
            "duration": "2 Jahre",
            "date": "4. März 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Augmented Reality"
            ],
            "detailedDescription": "<p>AR- und IoT-basierte Lernplattform für Mitarbeiter und Studenten.</p>"
        },
        {
            "id": 3,
            "title": "SubMerge",
            "description": "VR Unterwasser-Museum - Virtuelle Realität Unterwassererlebnis",
            "category": "web-app",
            "images": [
                "/images/hobby-project.png"
            ],
            "youtubeLink": "https://www.youtube.com/embed/9ubWJePQCwg",
            "github": "",
            "appLink": "https://drive.google.com/file/d/1SkCRXHEn5xs_H8E9z1KcGtNdg5EASb57/view?usp=drive_link",
            "purpose": "SIH (Software-Edition)",
            "duration": "2 Wochen",
            "date": "6. März 2022",
            "technologies": [
                "Unity",
                "Android App Dev",
                "Virtual Reality"
            ],
            "detailedDescription": "<p>Immersive VR-Anwendung für Android mit Unity und Google VR für interaktive Unterwassererlebnisse.</p>"
        },
        {
            "id": 2,
            "title": "Spikora",
            "description": "RosaryPlantHouse.com – E-Commerce-Webanwendung für Pflanzenliebhaber",
            "category": "web-app",
            "images": [
                "/images/hobby-project.png"
            ],
            "youtubeLink": "",
            "github": "",
            "appLink": "https://www.rosaryplanthouse.com",
            "purpose": "Rosary Plant House",
            "duration": "2 Wochen",
            "date": "7. März 2022",
            "technologies": [
                "HTML",
                "CSS",
                "JavaScript",
                "E-Commerce"
            ],
            "detailedDescription": "<p>Statische E-Commerce-Website für Pflanzenliebhaber mit WhatsApp-basiertem Checkout.</p>"
        }
    ]
}